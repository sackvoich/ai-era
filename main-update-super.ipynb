{
 "cells": [
  {
   "cell_type": "code",
   "id": "f24a4d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:15:46.722586Z",
     "start_time": "2025-09-28T12:15:11.570593Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "275d678a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:15:47.055128Z",
     "start_time": "2025-09-28T12:15:47.048114Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def super_clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 1. Транслит, как и было\n",
    "    cyrillic_map = str.maketrans(\"abvgdeziklmnoprstufhcy\", \"абвгдезиклмнопрстуфхцы\")\n",
    "    text = text.translate(cyrillic_map)\n",
    "    text = text.replace('blia', 'бля').replace('blya', 'бля').replace('ebat', 'ебать')\n",
    "\n",
    "    # 2. Агрессивное удаление разделителей между буквами\n",
    "    # Это найдет \"б л я т ь\", \"б.л.я.т.ь\", \"б-л.я т.ь\" и т.д.\n",
    "    # Мы ищем букву, за которой следует до 3-х символов-разделителей, и потом снова буква.\n",
    "    # И так повторяем.\n",
    "    def merge_separated_letters(match):\n",
    "        return match.group(0).replace('.', '').replace(' ', '').replace('-', '').replace('!', '').replace('@', '').replace('#', '').replace('$', '').replace('*', '')\n",
    "\n",
    "    text = re.sub(r'([а-яё])([\\s\\.\\-]+[а-яё]){2,}', merge_separated_letters, text)\n",
    "\n",
    "    # 3. Нормализация \"е\" и \"ё\"\n",
    "    text = text.replace('ё', 'е')\n",
    "    \n",
    "    # 4. Удаление повторяющихся букв (растянутость)\n",
    "    text = re.sub(r'([а-я])\\1+', r'\\1', text)\n",
    "    \n",
    "    # 5. Более умные замены звездочек и пропусков.\n",
    "    # Заменяем все, что похоже на мат, на его корень.\n",
    "    text = re.sub(r'х[уеё*@#$ ]{1,5}[йяиюе]', 'хуй', text)\n",
    "    text = re.sub(r'п[иеё*@#$ ]{1,5}[зс][д]', 'пизд', text)\n",
    "    text = re.sub(r'[её][б*@#$ ]{1,5}[аоуя]', 'еб', text)\n",
    "    text = re.sub(r'б[л*@#$ ]{1,5}[я]', 'бля', text)\n",
    "    text = re.sub(r'м[у*@#$ ]{1,5}[д][аеио]', 'муд', text)\n",
    "    \n",
    "    return text\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a4d954ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:15:47.089943Z",
     "start_time": "2025-09-28T12:15:47.083601Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "def augment_profanity(df):\n",
    "    profanity_samples = df[(df['label'] == 1) & (df['text'].str.contains(r'хуй|пизд|еб|бля|муд'))].copy()\n",
    "    if profanity_samples.empty:\n",
    "        return df\n",
    "\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in profanity_samples.iterrows():\n",
    "        text = row['text']\n",
    "        \n",
    "        # Вариант 1: Растягивание букв\n",
    "        if random.random() < 0.5:\n",
    "            words = text.split()\n",
    "            if not words: continue\n",
    "            word_to_stretch = random.choice(words)\n",
    "            if len(word_to_stretch) > 2:\n",
    "                char_to_stretch = random.choice(word_to_stretch)\n",
    "                stretched_word = word_to_stretch.replace(char_to_stretch, char_to_stretch * random.randint(3, 7))\n",
    "                new_text = text.replace(word_to_stretch, stretched_word)\n",
    "                new_rows.append({'text': new_text, 'label': 1})\n",
    "\n",
    "        # Вариант 2: Вставка разделителей\n",
    "        if random.random() < 0.5:\n",
    "            words = text.split()\n",
    "            if not words: continue\n",
    "            word_to_separate = random.choice(words)\n",
    "            if len(word_to_separate) > 2:\n",
    "                separator = random.choice(['.', ' ', '-', '*'])\n",
    "                separated_word = separator.join(list(word_to_separate))\n",
    "                new_text = text.replace(word_to_separate, separated_word)\n",
    "                new_rows.append({'text': new_text, 'label': 1})\n",
    "\n",
    "    if not new_rows:\n",
    "        return df\n",
    "        \n",
    "    augmented_df = pd.DataFrame(new_rows)\n",
    "    return pd.concat([df, augmented_df], ignore_index=True)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "681aad4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.053141Z",
     "start_time": "2025-09-28T12:15:47.109056Z"
    }
   },
   "source": [
    "# --- 1. Настройки и загрузка данных -1--\n",
    "MODEL_NAME = \"cointegrated/rubert-tiny2\" # Общая модель для всех, быстрая и качественная\n",
    "MAX_LENGTH = 256 # Длина текста, можно увеличить до 512, если отзывы длинные\n",
    "BATCH_SIZE = 16 # Уменьшайте до 8, если не хватает видеопамяти\n",
    "EPOCHS = 1 # 1 эпоха - для файн-тьюна\n",
    "\n",
    "print(\"Загрузка данных...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "#test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# ШАГ 1: АУГМЕНТАЦИЯ\n",
    "# Сначала аугментируем на \"чистых\" данных, чтобы создать \"грязные\" примеры\n",
    "print(\"Аугментация данных...\")\n",
    "# Запускаем аугментацию несколько раз, чтобы создать больше примеров\n",
    "augmented_train_df = train_df.copy()\n",
    "for i in range(5): # 3 прохода аугментации\n",
    "    print(f\"Проход аугментации №{i+1}\")\n",
    "    augmented_train_df = augment_profanity(augmented_train_df)\n",
    "print(f\"Размер датасета после аугментации: {len(augmented_train_df)}\")\n",
    "\n",
    "print(\"Применение супер-очистки к данным...\")\n",
    "augmented_train_df['text'] = augmented_train_df['text'].apply(super_clean_text)\n",
    "\n",
    "train_df = augmented_train_df\n",
    "\n",
    "# Очистка от пустых строк на всякий случай\n",
    "train_df.dropna(subset=['text'], inplace=True)\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "#test_df['text'] = test_df['text'].astype(str)\n",
    "\n",
    "print(\"Разделение на train/eval...\")\n",
    "# Стратифицированное разделение для сохранения баланса классов\n",
    "train_subset_df, eval_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.15, # 15% на валидацию\n",
    "    random_state=42,\n",
    "    stratify=train_df['label']\n",
    ")\n",
    "\n",
    "# Оставим полный train_df для финального обучения\n",
    "# train_subset_df - для быстрой проверки гипотез\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_subset_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "full_train_dataset = Dataset.from_pandas(train_df) # Для финального обучения\n",
    "#test_dataset = Dataset.from_pan     das(test_df)\n",
    "\n",
    "print(\"Инициализация токенизатора...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "print(\"Токенизация данных...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_full_train = full_train_dataset.map(tokenize_function, batched=True)\n",
    "#tokenized_test = test_dataset.map(tokenize_function, batched=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Аугментация данных...\n",
      "Проход аугментации №1\n",
      "Проход аугментации №2\n",
      "Проход аугментации №3\n",
      "Проход аугментации №4\n",
      "Проход аугментации №5\n",
      "Размер датасета после аугментации: 324122\n",
      "Применение супер-очистки к данным...\n",
      "Разделение на train/eval...\n",
      "Инициализация токенизатора...\n",
      "Токенизация данных...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/275503 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a04c5254203445c9cd383181de66e5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/48619 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "813708c792cf41498d1be383046744ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/324122 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c97a59e9ce894841b3b4067b0068abc2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "bdc170e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.126384Z",
     "start_time": "2025-09-28T12:17:10.122587Z"
    }
   },
   "source": [
    "# --- 2. Функция для метрики (общая для всех) ---\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1 = f1_score(labels, predictions, average='binary') # 'binary' для F1 по классу 1\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"f1\": f1, \"accuracy\": acc}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "1872039b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.503359Z",
     "start_time": "2025-09-28T12:17:10.199256Z"
    }
   },
   "source": [
    "# --- 3. Общие аргументы для обучения ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, # Очень важно!\n",
    "    metric_for_best_model=\"f1\", # Оптимизируемся по F1\n",
    "    greater_is_better=True,\n",
    "    fp16=torch.cuda.is_available(), # Автоматическое вкл. смешанной точности, если есть GPU\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "703acc7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.700175Z",
     "start_time": "2025-09-28T12:17:10.540653Z"
    }
   },
   "source": [
    "# --- Пайплайн 2: BERT с Weighted Loss ---\n",
    "print(\"\\n--- Запуск Пайплайна 2: BERT с Weighted Loss ---\")\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Расчет весов для классов ---\n",
    "print(\"Расчет весов для классов...\")\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Веса для классов: {class_weights_tensor}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Запуск Пайплайна 2: BERT с Weighted Loss ---\n",
      "Расчет весов для классов...\n",
      "Веса для классов: tensor([0.7700, 1.4258], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "712424735747edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.741994Z",
     "start_time": "2025-09-28T12:17:10.737961Z"
    }
   },
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    # Добавлен **kwargs для совместимости с новыми версиями Trainer\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Извлечение меток\n",
    "        labels = inputs.pop(\"labels\")\n",
    "\n",
    "        # Прямой проход модели\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Использование весов классов (предполагается, что class_weights_tensor определен)\n",
    "        # Убедитесь, что class_weights_tensor находится на том же устройстве (CPU/CUDA), что и logits\n",
    "        # class_weights_tensor = class_weights_tensor.to(logits.device)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "        # Вычисление взвешенных потерь\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, self.model.config.num_labels),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "fd4e4f8f7c82fcc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:38:49.457363Z",
     "start_time": "2025-09-28T12:17:10.793197Z"
    }
   },
   "source": [
    "# --- Кастомный Trainer ---\n",
    "import os\n",
    "\n",
    "\n",
    "# Сделайте так:\n",
    "# --- ИЗМЕНЕНИЯ ЗДЕСЬ ---\n",
    "# Указываем относительный путь как и раньше\n",
    "relative_path = \"./final_weighted_model-1\"\n",
    "# Преобразуем его в полный (абсолютный) путь, понятный системе\n",
    "SAVED_MODEL_PATH = os.path.abspath(relative_path)\n",
    "\n",
    "print(f\"Загрузка уже обученной модели из {SAVED_MODEL_PATH} для продолжения обучения...\")\n",
    "# Теперь from_pretrained поймет, что это локальная папка, а не репозиторий на хабе\n",
    "model_weighted = AutoModelForSequenceClassification.from_pretrained(SAVED_MODEL_PATH, num_labels=2, local_files_only=True)\n",
    "trainer_weighted = WeightedLossTrainer(\n",
    "    model=model_weighted,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Обучение модели с весами...\")\n",
    "trainer_weighted.train()\n",
    "\n",
    "print(\"Оценка модели с весами на валидации...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка уже обученной модели из C:\\Users\\malan\\PycharmProjects\\PythonProject\\final_weighted_model-1 для продолжения обучения...\n",
      "Обучение модели с весами...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17219' max='17219' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17219/17219 21:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.049812</td>\n",
       "      <td>0.985034</td>\n",
       "      <td>0.989531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка модели с весами на валидации...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "a228339e73d9f8c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:40:09.289867Z",
     "start_time": "2025-09-28T12:38:49.505459Z"
    }
   },
   "source": [
    "eval_results_weighted = trainer_weighted.evaluate()\n",
    "print(f\"Результаты валидации Weighted Loss: {eval_results_weighted}\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3039' max='3039' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3039/3039 01:19]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты валидации Weighted Loss: {'eval_loss': 0.04981185868382454, 'eval_f1': 0.9850342536238276, 'eval_accuracy': 0.9895308418519508, 'eval_runtime': 79.7776, 'eval_samples_per_second': 609.432, 'eval_steps_per_second': 38.093, 'epoch': 1.0}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "976e3622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T13:04:26.172162Z",
     "start_time": "2025-09-28T12:40:09.333451Z"
    }
   },
   "source": [
    "# --- Обучение на всех данных и предсказание ---\n",
    "print(\"Переобучение модели с весами на всех данных...\")\n",
    "\n",
    "# Создаем копию аргументов для финального обучения\n",
    "final_training_args_dict = training_args.to_dict()\n",
    "\n",
    "# --- ВНОСИМ ИЗМЕНЕНИЯ ДЛЯ ФИНАЛЬНОГО ОБУЧЕНИЯ ---\n",
    "# Отключаем оценку, т.к. eval_dataset не будет\n",
    "final_training_args_dict['eval_strategy'] = 'no'\n",
    "# Также отключаем сохранение по эпохам (сохраним один раз в конце)\n",
    "final_training_args_dict['save_strategy'] = 'no'\n",
    "# И загрузку лучшей модели, т.к. нет метрики для выбора\n",
    "final_training_args_dict['load_best_model_at_end'] = False\n",
    "\n",
    "# Преобразуем словарь обратно в объект TrainingArguments\n",
    "final_args = TrainingArguments(**final_training_args_dict)\n",
    "\n",
    "# Создаем финальный тренер с НОВЫМИ аргументами\n",
    "final_trainer_weighted = WeightedLossTrainer(\n",
    "    model=model_weighted,   # Используем уже дообученную модель с первого этапа!\n",
    "    args=final_args,        # Используем новые аргументы без валидации\n",
    "    train_dataset=tokenized_full_train,\n",
    "    # eval_dataset и compute_metrics здесь уже не нужны\n",
    ")\n",
    "\n",
    "# Запускаем финальное дообучение\n",
    "print(\"Запуск финального дообучения...\")\n",
    "final_trainer_weighted.train()\n",
    "\n",
    "print(\"Сохранение финальной модели...\")\n",
    "# Сохраняем модель и токенизатор в одну папку\n",
    "SAVE_PATH = \"./final_model_after_cleaning-2\"\n",
    "final_trainer_weighted.save_model(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "print(f\"Финальная модель и токенизатор сохранены в '{SAVE_PATH}'\")\n",
    "# --- Обучение на всех данных и предсказание ---\n",
    "# print(\"Переобучение модели с весами на всех данных...\")\n",
    "# final_trainer_weighted = WeightedLossTrainer(\n",
    "#     model=model_weighted,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_full_train,\n",
    "# )\n",
    "# final_trainer_weighted.train()\n",
    "\n",
    "#print(\"Предсказание для test.csv...\")\n",
    "#predictions_w, _, _ = final_trainer_weighted.predict(tokenized_test)\n",
    "#predicted_labels_w = np.argmax(predictions_w, axis=1)\n",
    "\n",
    "#submission_weighted = pd.DataFrame({'id': test_df['id'], 'label': predicted_labels_w})\n",
    "#submission_weighted.to_csv('submission_weighted.csv', index=False)\n",
    "#print(\"Файл submission_weighted.csv готов!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Переобучение модели с весами на всех данных...\n",
      "Запуск финального дообучения...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malan\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2093: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20258' max='20258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20258/20258 24:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.050900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.047600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.047200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.038100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.049600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.056600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.048700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15900</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16300</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16700</td>\n",
       "      <td>0.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16900</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17100</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17300</td>\n",
       "      <td>0.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17700</td>\n",
       "      <td>0.050400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17900</td>\n",
       "      <td>0.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18100</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18300</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18700</td>\n",
       "      <td>0.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19100</td>\n",
       "      <td>0.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19300</td>\n",
       "      <td>0.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19700</td>\n",
       "      <td>0.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19900</td>\n",
       "      <td>0.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20100</td>\n",
       "      <td>0.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20200</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение финальной модели...\n",
      "Финальная модель и токенизатор сохранены в './final_model_after_cleaning-2'\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T13:04:26.536768Z",
     "start_time": "2025-09-28T13:04:26.254119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Сохранение финальной модели...\")\n",
    "# Сохраняем модель и токенизатор в одну папку\n",
    "SAVE_PATH = \"./final_model_after_cleaning-2-15-08\"\n",
    "final_trainer_weighted.save_model(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "print(f\"Финальная модель и токенизатор сохранены в '{SAVE_PATH}'\")"
   ],
   "id": "3e01e6093ca8a433",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение финальной модели...\n",
      "Финальная модель и токенизатор сохранены в './final_model_after_cleaning-2-15-08'\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "f801833f93181051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T13:04:26.600147Z",
     "start_time": "2025-09-28T13:04:26.592602Z"
    }
   },
   "source": [
    "# # --- Обучение на всех данных и предсказание ---\n",
    "# print(\"Переобучение модели с весами на всех данных...\")\n",
    "#\n",
    "# # Создаем копию аргументов для финального обучения\n",
    "# final_training_args = training_args.to_dict()\n",
    "#\n",
    "# # Отключаем оценку и сохранение по шагам, т.к. eval_dataset не будет\n",
    "# final_training_args['eval_strategy'] = 'no'\n",
    "# final_training_args['save_strategy'] = 'no'\n",
    "# # Также отключаем загрузку лучшей модели, т.к. нет метрики для выбора\n",
    "# final_training_args['load_best_model_at_end'] = False\n",
    "#\n",
    "# # Преобразуем словарь обратно в TrainingArguments\n",
    "# final_args = TrainingArguments(**final_training_args)\n",
    "#\n",
    "#\n",
    "# # Создаем финальный тренер с новыми аргументами\n",
    "# final_trainer_weighted = WeightedLossTrainer(\n",
    "#     model=model_weighted,   # Используем уже дообученную и лучшую модель с первого этапа!\n",
    "#     args=final_args,        # Используем новые аргументы без валидации\n",
    "#     train_dataset=tokenized_full_train,\n",
    "#     # eval_dataset и compute_metrics здесь не нужны\n",
    "# )\n",
    "#\n",
    "# # Запускаем финальное дообучение\n",
    "# final_trainer_weighted.train()\n",
    "#\n",
    "# print(\"Сохранение финальной модели...\")\n",
    "# # Модель сохраняется в папку, указанную в output_dir\n",
    "# final_trainer_weighted.save_model(\"./final_weighted_model\")\n",
    "# tokenizer.save_pretrained(\"./final_weighted_model\") # Сохраняем и токенизатор рядом\n",
    "#\n",
    "# print(\"Предсказание для test.csv...\")\n",
    "# predictions_w = final_trainer_weighted.predict(tokenized_test)\n",
    "# predicted_labels_w = np.argmax(predictions_w.predictions, axis=1)\n",
    "#\n",
    "# submission_weighted = pd.DataFrame({'id': test_df['id'], 'label': predicted_labels_w})\n",
    "# submission_weighted.to_csv('submission_weighted.csv', index=False)\n",
    "# print(\"Файл submission_weighted.csv и модель в ./final_weighted_model готовы!\")"
   ],
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
