{
 "cells": [
  {
   "cell_type": "code",
   "id": "f24a4d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:15:46.722586Z",
     "start_time": "2025-09-28T12:15:11.570593Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "275d678a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:15:47.055128Z",
     "start_time": "2025-09-28T12:15:47.048114Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def super_clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 1. –¢—Ä–∞–Ω—Å–ª–∏—Ç, –∫–∞–∫ –∏ –±—ã–ª–æ\n",
    "    cyrillic_map = str.maketrans(\"abvgdeziklmnoprstufhcy\", \"–∞–±–≤–≥–¥–µ–∑–∏–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—ã\")\n",
    "    text = text.translate(cyrillic_map)\n",
    "    text = text.replace('blia', '–±–ª—è').replace('blya', '–±–ª—è').replace('ebat', '–µ–±–∞—Ç—å')\n",
    "\n",
    "    # 2. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏\n",
    "    # –≠—Ç–æ –Ω–∞–π–¥–µ—Ç \"–± –ª —è —Ç —å\", \"–±.–ª.—è.—Ç.—å\", \"–±-–ª.—è —Ç.—å\" –∏ —Ç.–¥.\n",
    "    # –ú—ã –∏—â–µ–º –±—É–∫–≤—É, –∑–∞ –∫–æ—Ç–æ—Ä–æ–π —Å–ª–µ–¥—É–µ—Ç –¥–æ 3-—Ö —Å–∏–º–≤–æ–ª–æ–≤-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π, –∏ –ø–æ—Ç–æ–º —Å–Ω–æ–≤–∞ –±—É–∫–≤–∞.\n",
    "    # –ò —Ç–∞–∫ –ø–æ–≤—Ç–æ—Ä—è–µ–º.\n",
    "    def merge_separated_letters(match):\n",
    "        return match.group(0).replace('.', '').replace(' ', '').replace('-', '').replace('!', '').replace('@', '').replace('#', '').replace('$', '').replace('*', '')\n",
    "\n",
    "    text = re.sub(r'([–∞-—è—ë])([\\s\\.\\-]+[–∞-—è—ë]){2,}', merge_separated_letters, text)\n",
    "\n",
    "    # 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è \"–µ\" –∏ \"—ë\"\n",
    "    text = text.replace('—ë', '–µ')\n",
    "    \n",
    "    # 4. –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –±—É–∫–≤ (—Ä–∞—Å—Ç—è–Ω—É—Ç–æ—Å—Ç—å)\n",
    "    text = re.sub(r'([–∞-—è])\\1+', r'\\1', text)\n",
    "    \n",
    "    # 5. –ë–æ–ª–µ–µ —É–º–Ω—ã–µ –∑–∞–º–µ–Ω—ã –∑–≤–µ–∑–¥–æ—á–µ–∫ –∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤.\n",
    "    # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ, —á—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –º–∞—Ç, –Ω–∞ –µ–≥–æ –∫–æ—Ä–µ–Ω—å.\n",
    "    text = re.sub(r'—Ö[—É–µ—ë*@#$ ]{1,5}[–π—è–∏—é–µ]', '—Ö—É–π', text)\n",
    "    text = re.sub(r'–ø[–∏–µ—ë*@#$ ]{1,5}[–∑—Å][–¥]', '–ø–∏–∑–¥', text)\n",
    "    text = re.sub(r'[–µ—ë][–±*@#$ ]{1,5}[–∞–æ—É—è]', '–µ–±', text)\n",
    "    text = re.sub(r'–±[–ª*@#$ ]{1,5}[—è]', '–±–ª—è', text)\n",
    "    text = re.sub(r'–º[—É*@#$ ]{1,5}[–¥][–∞–µ–∏–æ]', '–º—É–¥', text)\n",
    "    \n",
    "    return text\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a4d954ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:15:47.089943Z",
     "start_time": "2025-09-28T12:15:47.083601Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "def augment_profanity(df):\n",
    "    profanity_samples = df[(df['label'] == 1) & (df['text'].str.contains(r'—Ö—É–π|–ø–∏–∑–¥|–µ–±|–±–ª—è|–º—É–¥'))].copy()\n",
    "    if profanity_samples.empty:\n",
    "        return df\n",
    "\n",
    "    new_rows = []\n",
    "    \n",
    "    for _, row in profanity_samples.iterrows():\n",
    "        text = row['text']\n",
    "        \n",
    "        # –í–∞—Ä–∏–∞–Ω—Ç 1: –†–∞—Å—Ç—è–≥–∏–≤–∞–Ω–∏–µ –±—É–∫–≤\n",
    "        if random.random() < 0.5:\n",
    "            words = text.split()\n",
    "            if not words: continue\n",
    "            word_to_stretch = random.choice(words)\n",
    "            if len(word_to_stretch) > 2:\n",
    "                char_to_stretch = random.choice(word_to_stretch)\n",
    "                stretched_word = word_to_stretch.replace(char_to_stretch, char_to_stretch * random.randint(3, 7))\n",
    "                new_text = text.replace(word_to_stretch, stretched_word)\n",
    "                new_rows.append({'text': new_text, 'label': 1})\n",
    "\n",
    "        # –í–∞—Ä–∏–∞–Ω—Ç 2: –í—Å—Ç–∞–≤–∫–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π\n",
    "        if random.random() < 0.5:\n",
    "            words = text.split()\n",
    "            if not words: continue\n",
    "            word_to_separate = random.choice(words)\n",
    "            if len(word_to_separate) > 2:\n",
    "                separator = random.choice(['.', ' ', '-', '*'])\n",
    "                separated_word = separator.join(list(word_to_separate))\n",
    "                new_text = text.replace(word_to_separate, separated_word)\n",
    "                new_rows.append({'text': new_text, 'label': 1})\n",
    "\n",
    "    if not new_rows:\n",
    "        return df\n",
    "        \n",
    "    augmented_df = pd.DataFrame(new_rows)\n",
    "    return pd.concat([df, augmented_df], ignore_index=True)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "681aad4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.053141Z",
     "start_time": "2025-09-28T12:15:47.109056Z"
    }
   },
   "source": [
    "# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö -1--\n",
    "MODEL_NAME = \"cointegrated/rubert-tiny2\" # –û–±—â–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≤—Å–µ—Ö, –±—ã—Å—Ç—Ä–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è\n",
    "MAX_LENGTH = 256 # –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 512, –µ—Å–ª–∏ –æ—Ç–∑—ã–≤—ã –¥–ª–∏–Ω–Ω—ã–µ\n",
    "BATCH_SIZE = 16 # –£–º–µ–Ω—å—à–∞–π—Ç–µ –¥–æ 8, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏\n",
    "EPOCHS = 1 # 1 —ç–ø–æ—Ö–∞ - –¥–ª—è —Ñ–∞–π–Ω-—Ç—å—é–Ω–∞\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "#test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# –®–ê–ì 1: –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø\n",
    "# –°–Ω–∞—á–∞–ª–∞ –∞—É–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –Ω–∞ \"—á–∏—Å—Ç—ã—Ö\" –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å \"–≥—Ä—è–∑–Ω—ã–µ\" –ø—Ä–∏–º–µ—Ä—ã\n",
    "print(\"–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –±–æ–ª—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "augmented_train_df = train_df.copy()\n",
    "for i in range(5): # 3 –ø—Ä–æ—Ö–æ–¥–∞ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "    print(f\"–ü—Ä–æ—Ö–æ–¥ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Ññ{i+1}\")\n",
    "    augmented_train_df = augment_profanity(augmented_train_df)\n",
    "print(f\"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {len(augmented_train_df)}\")\n",
    "\n",
    "print(\"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—É–ø–µ—Ä-–æ—á–∏—Å—Ç–∫–∏ –∫ –¥–∞–Ω–Ω—ã–º...\")\n",
    "augmented_train_df['text'] = augmented_train_df['text'].apply(super_clean_text)\n",
    "\n",
    "train_df = augmented_train_df\n",
    "\n",
    "# –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π\n",
    "train_df.dropna(subset=['text'], inplace=True)\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "#test_df['text'] = test_df['text'].astype(str)\n",
    "\n",
    "print(\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/eval...\")\n",
    "# –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "train_subset_df, eval_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.15, # 15% –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é\n",
    "    random_state=42,\n",
    "    stratify=train_df['label']\n",
    ")\n",
    "\n",
    "# –û—Å—Ç–∞–≤–∏–º –ø–æ–ª–Ω—ã–π train_df –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "# train_subset_df - –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–∏–ø–æ—Ç–µ–∑\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_subset_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "full_train_dataset = Dataset.from_pandas(train_df) # –î–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "#test_dataset = Dataset.from_pan     das(test_df)\n",
    "\n",
    "print(\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "print(\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_full_train = full_train_dataset.map(tokenize_function, batched=True)\n",
    "#tokenized_test = test_dataset.map(tokenize_function, batched=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n",
      "–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...\n",
      "–ü—Ä–æ—Ö–æ–¥ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Ññ1\n",
      "–ü—Ä–æ—Ö–æ–¥ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Ññ2\n",
      "–ü—Ä–æ—Ö–æ–¥ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Ññ3\n",
      "–ü—Ä–æ—Ö–æ–¥ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Ññ4\n",
      "–ü—Ä–æ—Ö–æ–¥ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Ññ5\n",
      "–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: 324122\n",
      "–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—É–ø–µ—Ä-–æ—á–∏—Å—Ç–∫–∏ –∫ –¥–∞–Ω–Ω—ã–º...\n",
      "–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/eval...\n",
      "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...\n",
      "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/275503 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a04c5254203445c9cd383181de66e5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/48619 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "813708c792cf41498d1be383046744ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/324122 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c97a59e9ce894841b3b4067b0068abc2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "bdc170e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.126384Z",
     "start_time": "2025-09-28T12:17:10.122587Z"
    }
   },
   "source": [
    "# --- 2. –§—É–Ω–∫—Ü–∏—è –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ (–æ–±—â–∞—è –¥–ª—è –≤—Å–µ—Ö) ---\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1 = f1_score(labels, predictions, average='binary') # 'binary' –¥–ª—è F1 –ø–æ –∫–ª–∞—Å—Å—É 1\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"f1\": f1, \"accuracy\": acc}"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "1872039b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.503359Z",
     "start_time": "2025-09-28T12:17:10.199256Z"
    }
   },
   "source": [
    "# --- 3. –û–±—â–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True, # –û—á–µ–Ω—å –≤–∞–∂–Ω–æ!\n",
    "    metric_for_best_model=\"f1\", # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º—Å—è –ø–æ F1\n",
    "    greater_is_better=True,\n",
    "    fp16=torch.cuda.is_available(), # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–∫–ª. —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –µ—Å—Ç—å GPU\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "703acc7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.700175Z",
     "start_time": "2025-09-28T12:17:10.540653Z"
    }
   },
   "source": [
    "# --- –ü–∞–π–ø–ª–∞–π–Ω 2: BERT —Å Weighted Loss ---\n",
    "print(\"\\n--- –ó–∞–ø—É—Å–∫ –ü–∞–π–ø–ª–∞–π–Ω–∞ 2: BERT —Å Weighted Loss ---\")\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ ---\n",
    "print(\"–†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤...\")\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"–í–µ—Å–∞ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤: {class_weights_tensor}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- –ó–∞–ø—É—Å–∫ –ü–∞–π–ø–ª–∞–π–Ω–∞ 2: BERT —Å Weighted Loss ---\n",
      "–†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤...\n",
      "–í–µ—Å–∞ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤: tensor([0.7700, 1.4258], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "712424735747edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:17:10.741994Z",
     "start_time": "2025-09-28T12:17:10.737961Z"
    }
   },
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    # –î–æ–±–∞–≤–ª–µ–Ω **kwargs –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –Ω–æ–≤—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ Trainer\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫\n",
    "        labels = inputs.pop(\"labels\")\n",
    "\n",
    "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –º–æ–¥–µ–ª–∏\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ class_weights_tensor –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)\n",
    "        # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ class_weights_tensor –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —Ç–æ–º –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ (CPU/CUDA), —á—Ç–æ –∏ logits\n",
    "        # class_weights_tensor = class_weights_tensor.to(logits.device)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–∑–≤–µ—à–µ–Ω–Ω—ã—Ö –ø–æ—Ç–µ—Ä—å\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, self.model.config.num_labels),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "fd4e4f8f7c82fcc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:38:49.457363Z",
     "start_time": "2025-09-28T12:17:10.793197Z"
    }
   },
   "source": [
    "# --- –ö–∞—Å—Ç–æ–º–Ω—ã–π Trainer ---\n",
    "import os\n",
    "\n",
    "\n",
    "# –°–¥–µ–ª–∞–π—Ç–µ —Ç–∞–∫:\n",
    "# --- –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ó–î–ï–°–¨ ---\n",
    "# –£–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ\n",
    "relative_path = \"./final_weighted_model-1\"\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ–≥–æ –≤ –ø–æ–ª–Ω—ã–π (–∞–±—Å–æ–ª—é—Ç–Ω—ã–π) –ø—É—Ç—å, –ø–æ–Ω—è—Ç–Ω—ã–π —Å–∏—Å—Ç–µ–º–µ\n",
    "SAVED_MODEL_PATH = os.path.abspath(relative_path)\n",
    "\n",
    "print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ {SAVED_MODEL_PATH} –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è...\")\n",
    "# –¢–µ–ø–µ—Ä—å from_pretrained –ø–æ–π–º–µ—Ç, —á—Ç–æ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω–∞—è –ø–∞–ø–∫–∞, –∞ –Ω–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ —Ö–∞–±–µ\n",
    "model_weighted = AutoModelForSequenceClassification.from_pretrained(SAVED_MODEL_PATH, num_labels=2, local_files_only=True)\n",
    "trainer_weighted = WeightedLossTrainer(\n",
    "    model=model_weighted,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏...\")\n",
    "trainer_weighted.train()\n",
    "\n",
    "print(\"–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ C:\\Users\\malan\\PycharmProjects\\PythonProject\\final_weighted_model-1 –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è...\n",
      "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17219' max='17219' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17219/17219 21:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.049812</td>\n",
       "      <td>0.985034</td>\n",
       "      <td>0.989531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "a228339e73d9f8c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:40:09.289867Z",
     "start_time": "2025-09-28T12:38:49.505459Z"
    }
   },
   "source": [
    "eval_results_weighted = trainer_weighted.evaluate()\n",
    "print(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Weighted Loss: {eval_results_weighted}\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3039' max='3039' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3039/3039 01:19]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Weighted Loss: {'eval_loss': 0.04981185868382454, 'eval_f1': 0.9850342536238276, 'eval_accuracy': 0.9895308418519508, 'eval_runtime': 79.7776, 'eval_samples_per_second': 609.432, 'eval_steps_per_second': 38.093, 'epoch': 1.0}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "976e3622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T13:04:26.172162Z",
     "start_time": "2025-09-28T12:40:09.333451Z"
    }
   },
   "source": [
    "# --- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ---\n",
    "print(\"–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "final_training_args_dict = training_args.to_dict()\n",
    "\n",
    "# --- –í–ù–û–°–ò–ú –ò–ó–ú–ï–ù–ï–ù–ò–Ø –î–õ–Ø –§–ò–ù–ê–õ–¨–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø ---\n",
    "# –û—Ç–∫–ª—é—á–∞–µ–º –æ—Ü–µ–Ω–∫—É, —Ç.–∫. eval_dataset –Ω–µ –±—É–¥–µ—Ç\n",
    "final_training_args_dict['eval_strategy'] = 'no'\n",
    "# –¢–∞–∫–∂–µ –æ—Ç–∫–ª—é—á–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ —ç–ø–æ—Ö–∞–º (—Å–æ—Ö—Ä–∞–Ω–∏–º –æ–¥–∏–Ω —Ä–∞–∑ –≤ –∫–æ–Ω—Ü–µ)\n",
    "final_training_args_dict['save_strategy'] = 'no'\n",
    "# –ò –∑–∞–≥—Ä—É–∑–∫—É –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏, —Ç.–∫. –Ω–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞\n",
    "final_training_args_dict['load_best_model_at_end'] = False\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ–±—ä–µ–∫—Ç TrainingArguments\n",
    "final_args = TrainingArguments(**final_training_args_dict)\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä —Å –ù–û–í–´–ú–ò –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏\n",
    "final_trainer_weighted = WeightedLossTrainer(\n",
    "    model=model_weighted,   # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å –ø–µ—Ä–≤–æ–≥–æ —ç—Ç–∞–ø–∞!\n",
    "    args=final_args,        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –±–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    train_dataset=tokenized_full_train,\n",
    "    # eval_dataset –∏ compute_metrics –∑–¥–µ—Å—å —É–∂–µ –Ω–µ –Ω—É–∂–Ω—ã\n",
    ")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ\n",
    "print(\"–ó–∞–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è...\")\n",
    "final_trainer_weighted.train()\n",
    "\n",
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤ –æ–¥–Ω—É –ø–∞–ø–∫—É\n",
    "SAVE_PATH = \"./final_model_after_cleaning-2\"\n",
    "final_trainer_weighted.save_model(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "print(f\"–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ '{SAVE_PATH}'\")\n",
    "# --- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ---\n",
    "# print(\"–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "# final_trainer_weighted = WeightedLossTrainer(\n",
    "#     model=model_weighted,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_full_train,\n",
    "# )\n",
    "# final_trainer_weighted.train()\n",
    "\n",
    "#print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è test.csv...\")\n",
    "#predictions_w, _, _ = final_trainer_weighted.predict(tokenized_test)\n",
    "#predicted_labels_w = np.argmax(predictions_w, axis=1)\n",
    "\n",
    "#submission_weighted = pd.DataFrame({'id': test_df['id'], 'label': predicted_labels_w})\n",
    "#submission_weighted.to_csv('submission_weighted.csv', index=False)\n",
    "#print(\"–§–∞–π–ª submission_weighted.csv –≥–æ—Ç–æ–≤!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "–ó–∞–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malan\\PycharmProjects\\PythonProject\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2093: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20258' max='20258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20258/20258 24:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.050900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.047600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.047200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.038100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.049600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.056600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.048700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.042700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.045300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15900</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16300</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16700</td>\n",
       "      <td>0.042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16900</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17100</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17300</td>\n",
       "      <td>0.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17700</td>\n",
       "      <td>0.050400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17900</td>\n",
       "      <td>0.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18100</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18300</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18700</td>\n",
       "      <td>0.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19100</td>\n",
       "      <td>0.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19300</td>\n",
       "      <td>0.041500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19700</td>\n",
       "      <td>0.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19900</td>\n",
       "      <td>0.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20100</td>\n",
       "      <td>0.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20200</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...\n",
      "–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ './final_model_after_cleaning-2'\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T13:04:26.536768Z",
     "start_time": "2025-09-28T13:04:26.254119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤ –æ–¥–Ω—É –ø–∞–ø–∫—É\n",
    "SAVE_PATH = \"./final_model_after_cleaning-2-15-08\"\n",
    "final_trainer_weighted.save_model(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "print(f\"–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ '{SAVE_PATH}'\")"
   ],
   "id": "3e01e6093ca8a433",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...\n",
      "–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ './final_model_after_cleaning-2-15-08'\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "f801833f93181051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T13:04:26.600147Z",
     "start_time": "2025-09-28T13:04:26.592602Z"
    }
   },
   "source": [
    "# # --- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ---\n",
    "# print(\"–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "#\n",
    "# # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "# final_training_args = training_args.to_dict()\n",
    "#\n",
    "# # –û—Ç–∫–ª—é—á–∞–µ–º –æ—Ü–µ–Ω–∫—É –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ —à–∞–≥–∞–º, —Ç.–∫. eval_dataset –Ω–µ –±—É–¥–µ—Ç\n",
    "# final_training_args['eval_strategy'] = 'no'\n",
    "# final_training_args['save_strategy'] = 'no'\n",
    "# # –¢–∞–∫–∂–µ –æ—Ç–∫–ª—é—á–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏, —Ç.–∫. –Ω–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞\n",
    "# final_training_args['load_best_model_at_end'] = False\n",
    "#\n",
    "# # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –æ–±—Ä–∞—Ç–Ω–æ –≤ TrainingArguments\n",
    "# final_args = TrainingArguments(**final_training_args)\n",
    "#\n",
    "#\n",
    "# # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä —Å –Ω–æ–≤—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏\n",
    "# final_trainer_weighted = WeightedLossTrainer(\n",
    "#     model=model_weighted,   # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –∏ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å —Å –ø–µ—Ä–≤–æ–≥–æ —ç—Ç–∞–ø–∞!\n",
    "#     args=final_args,        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –±–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "#     train_dataset=tokenized_full_train,\n",
    "#     # eval_dataset –∏ compute_metrics –∑–¥–µ—Å—å –Ω–µ –Ω—É–∂–Ω—ã\n",
    "# )\n",
    "#\n",
    "# # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ\n",
    "# final_trainer_weighted.train()\n",
    "#\n",
    "# print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...\")\n",
    "# # –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –ø–∞–ø–∫—É, —É–∫–∞–∑–∞–Ω–Ω—É—é –≤ output_dir\n",
    "# final_trainer_weighted.save_model(\"./final_weighted_model\")\n",
    "# tokenizer.save_pretrained(\"./final_weighted_model\") # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Ä—è–¥–æ–º\n",
    "#\n",
    "# print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è test.csv...\")\n",
    "# predictions_w = final_trainer_weighted.predict(tokenized_test)\n",
    "# predicted_labels_w = np.argmax(predictions_w.predictions, axis=1)\n",
    "#\n",
    "# submission_weighted = pd.DataFrame({'id': test_df['id'], 'label': predicted_labels_w})\n",
    "# submission_weighted.to_csv('submission_weighted.csv', index=False)\n",
    "# print(\"–§–∞–π–ª submission_weighted.csv –∏ –º–æ–¥–µ–ª—å –≤ ./final_weighted_model –≥–æ—Ç–æ–≤—ã!\")"
   ],
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
